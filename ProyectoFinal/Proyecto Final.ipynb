{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final: Procesamiento de Lenguaje Natural\n",
    "\n",
    "## Definición del proyecto\n",
    "\n",
    "El objetivo de este proyecto es utilizar una Red Neuronal Recurrente usando LSTM (Long-Short Term Memory) para hacer traducción de Inglés a Italiano. En los datos de entrenamiento que se nos proporcionan tenemos un par de frases; la frase en inglés y su correspondiente traducción a italiano. \n",
    "\n",
    "Para lograr esto, utilizaremos una red \"Sequence to Sequence\" en el que tendremos dos redes neuronales recurrentes para transformar una secuencia en otra; la primera nos servira como un \"Encoder\" para transofrmar una entrada de text a un vector mientras que la segunda nos servira para poder\n",
    "\n",
    "![Red Sequence-Sequence](./imagenes/encoder-decoder.png)\n",
    "\n",
    "## Requerimientos\n",
    "\n",
    "Para poder realizar este proyecto decidimos usar PyTorch para poder utilizar tensores y aprovechar el GPU de la computadora para el procesamiento (algo que con numpy no se puede hacer). La versión de Pytorch que utilizamos para este proyecto tiene las siguientes caracteristicas:\n",
    " - Version 1.1\n",
    " - Windows 10\n",
    " - Cuda 10.1\n",
    " - Python 3.7\n",
    " - Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pytorch torchvision cudatoolkit=10.0 -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Importamos todas la bibliotecas que vamos a estar utilizando. En este proeycto utilizaremos algunas librerias generales como lo son `string` y `re` que son de uso común durante cualquier proyecto de procesamiento de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Cargamos torch\n",
    "import torch\n",
    "# Cargamos la biblioteca de redes neuronales de pytorch\n",
    "import torch.nn as nn\n",
    "# Biblioteca de optimización de algoritmos\n",
    "from torch import optim\n",
    "# Funciones para entrenar la red neuronal.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Buscamos si el dispositivo donde se ejecuita el algoritmo tiene cuda instalado\n",
    "# en caso de que no lo tenga usará el CPU para el entrenamiento.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de texto\n",
    "En este proyecto el proceso de carga de texto se realiza utilizando pares de frases la primera en inglés seguido de un tab y despues en italiano.\n",
    "\n",
    "```\n",
    "we therefore respect whatever parliament may decide \tquindi noi rispettiamo le eventuali decisioni in materia del parlamento\n",
    "\n",
    "```\n",
    "\n",
    "Como vimos en clase la primera etapa será construir nuestros vectores one hot de las palabras que contiene el corpus de entrenamiento. Para esto generaremos un indice unico para cada una de las palabras el cual utilizará para ubicarse dentro del vector. \n",
    "\n",
    "![One Hot](./imagenes/onehot.png)\n",
    "\n",
    "Lo primero que haremos sera crear todas las funciones para limpiar los datos. Primero, pasamos de Unicode a ASCII y después normalizamos el texto quitando los simbolos especiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(w):\n",
    "    \"\"\"Transforma la palabra de entrada de Unicode a Ascii \n",
    "    basado en https://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "    \n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', w)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeStr(s):\n",
    "    \"\"\"Elimina signos de puntuación y transforma el string a minúsculas\"\"\"\n",
    "    \n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarrollamos una clase llamada Lenguaje, el cual contendrá el las funciones necesarias para pasar de la palabra al indíce y del indice de regreso a la palabra utilizando diccionarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defininimos lot tokens de inciio de oracion y de fin de oracion\n",
    "BOS = 0\n",
    "EOS = 1\n",
    "\n",
    "class Language:\n",
    "    \"\"\"\n",
    "    Esta clase sirve para agregar las palabras al diccionario y asignarles un \n",
    "    indice. Cuenta con las funciones necesarias tanto para pasar de un indice\n",
    "    a una palabra como de una palabara a un indice.\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        \"\"\"Inicializa las variables locales de la clase que son los diccionarios en los \n",
    "        que se almacena la informacion de las palabras\"\"\"\n",
    "        self.name = name\n",
    "        self.word2index={} # Nos servirá para convertir de una palabra a un índice\n",
    "        self.word2count={} # Nos servira para contar la frecuencia en que aparece una palabra\n",
    "        self.index2word={} # Nos servirá para pasar de un índice a una palabra\n",
    "        self.total = 2     # Noss servirá para contar el total de palabras únicas\n",
    "        \n",
    "    def procSentences(self, sentence):\n",
    "        \"\"\"Procesa una oración para ser agregada a los diccionarios del lenguaje\"\"\"\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        \"\"\"Agrega las palabras a los diccionarios y actualiza los contadores\"\"\"\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.total\n",
    "            self.word2count[word] = 1 \n",
    "            self.index2word[self.total] = word\n",
    "            self.total += 1\n",
    "        \n",
    "        else:\n",
    "            self.word2count[word] += 1  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos la función que nos permitirá leer las frases que vienen en el archivo de entrenamiento y las almacene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(lang1, lang2, reverse=False):\n",
    "    \"\"\"Lee el archivo de entrenamiento del traductor, lo limpia y asigna una clase Language\n",
    "    para almacenar los datos del lenguaje. Se permite revertir el orden para realizar pruebas\n",
    "    traduciendo de manera inversa el lenguaje.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading Files...\")\n",
    "\n",
    "    # Abrimos el archivo y lo dividmos por salto de linea para obtener\n",
    "    # los pares en una sola linea.\n",
    "    lines = open('./corpus/data3.test', encoding='utf-8').read().strip().split('\\n')\n",
    "    #print(\"Found {} lines\".format(len(lines)))\n",
    "\n",
    "    # Dividimos los pares en una linea en su lenguaje de entrada y lenguaje de salida\n",
    "    pairs = [[normalizeStr(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Instanceamos las clases Lang\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Language(lang2)\n",
    "        output_lang = Language(lang1)\n",
    "    else:\n",
    "        input_lang = Language(lang1)\n",
    "        output_lang = Language(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos del set de entrenamieto a dos clases de tipo Language: input(inglés) y output(italiano). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Files...\n",
      "Read 900 sentence pairs\n",
      "Trimmed to 897 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3276\n",
      "ita 4389\n",
      "['the vote will take place tomorrow at pm', 'la votazione si svolgera domani alle']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readFile(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.procSentences(pair[0])\n",
    "        output_lang.procSentences(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.total)\n",
    "    print(output_lang.name, output_lang.total)\n",
    "    return output_lang, input_lang, pairs\n",
    "\n",
    "\n",
    "output_lang, input_lang, pairs = prepareData('eng', 'ita', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Language at 0x23c02418fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal Recurrente (RNN)\n",
    "Una red neuronal recurrente es un tipo de red que utiliza secuancias para preoducir una salida tomando en cuenta la organización de la entrada de la red. Uno de los principales retos con las RNN es que el modelo de la red normalmente produce como máximo una salida por cada dato de entrada y en el ejemplo de traducción tenemos palabras que pueden producir más de una salida por lo que el modelo tradicional de RNN no nos es completamente útil para traducción.\n",
    "\n",
    "### Seq2Seq (Encoder-Decoder)\n",
    "Para solucionar esto, utilizaremos dos RNR una que nos servirá de encoder y otra que nos servirá de decoder de la traducción. El objetivo con esto es que sin importar la longitud de la frase de entrada o su organización, en cuanto a la posición de las palabras en el texto, podamos hacer la traducción de la manera más precisa posible. Esto se logra generando un vector intermedio en el que se intenta almacenar el significado de la frase de entrada a través del encoder y despues este significado es interpretado por el decoder en la salida.\n",
    "\n",
    "![encoder-decoder](./imagenes/paper-encode.png)\n",
    "\n",
    "Al final, viendo la imagen #1 del Notebook, no importa si la entrada es `le chat es noir` o `le chat noir` como el significado es el mismo debería producir el mismo resultado.\n",
    "\n",
    "### Encoder\n",
    "\n",
    "Un encoder de una red seq2seq utiliza el la secuanciaq de datos de entrada para generar un estado oculto el cual se va actualizando y se utriliza para el siguiente dato de entrada.\n",
    "\n",
    "Para el encoder usaremos una unidad GRU (Unidad Recurrente multicapa con compuertas), la cual, para cada una de las entradas, hará el siguiente cálculo.\n",
    "\n",
    "\\begin{array}{ll}\n",
    "            r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
    "            z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
    "            n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
    "            h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}\n",
    "\\end{array}\n",
    "\n",
    "Donde:\n",
    "\\begin{array}{ll}\n",
    "     h_{(t)} -> \\text{Estado oculto en el tiempo t}\\\\\n",
    "     x_t -> \\text{La entrada en el tiempo t} \\\\\n",
    "     h_{(t-1)} -> \\text{Estado oculto en el tiempo t-1 o el inicial para t=0} \\\\\n",
    "     z_t -> \\text{Gate de actualización} \\\\\n",
    "     r_t -> \\text{Gate de reset} \\\\\n",
    "     n_t -> \\text{}\\\\\n",
    "     \\sigma -> \\text{Funcion sigmoide} \\\\\n",
    "     * -> \\text{Producto de Hadamard} \\\\\n",
    "\\end{array}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Clase encoder que toma un vector de entrada y lo embede para aplicar la unidad \n",
    "    recurrente y terminar generando un vector de salida y un vector de capa oculta\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"Inicicaliza el encode con el tamaño que asignemos para el vector de la capa oculta\"\"\"\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"Programamos el forward para obtener el output y el hidden vector\"\"\"\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"Inicializa el vector de la capa oculta con ceros\"\"\"\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Decodificador\n",
    "En este caso vamos a hacer que el decosder tome dos parte del encoder: el vector de salida que generó el encoder al cual le llamaremos el vector de contexto que se utilizará como la inicialización de la capa oculta en el decodificador.\n",
    "\n",
    "Los paso del decodificador serán los siguientes:\n",
    " 1. Embedding del input\n",
    " 2. Aplicamos RELU al embedding\n",
    " 3. Aplicamos la unidad GRU y obtenemos un output y una capa oculta\n",
    " 4. al output aplicamos un softmax \n",
    " \n",
    "Recordando que:\n",
    " \n",
    " $\\text{ReLu} -> f(x)=max(0, x)$\n",
    " \n",
    " $\\text{Linear}-> y = xA^T + b$\n",
    " \n",
    " $\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"Esta clase aimplementa un decoder sencillo que utiliza un vector de contexto y un \n",
    "    vector de entrada que provienen del encoder.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        \"\"\"Inicializamos la capa oculta del decodificador y las funciones como \n",
    "        parte del decoder.\"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"Hacemos el forward de la neurona con los pasos explicados previamente\"\"\"\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"Inicializamos el vector de la capa oculta con ceros.\"\"\"\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decodificador con Atención\n",
    "Un problema que tiene el modelo anterior es que considera el mismo peso para todas las entradas del vector de contexto por lo que si damos pesos distintos a cada uno de las casillas de los vectores dependiendo de su relevancia en la frase podremos obtener una optimización al momento de traducir ya que el decodificador podrá enfocarse únicamente en una parte del vector de contexto. A esto se le llama `aplicacion de atención`. \n",
    "\n",
    "Para hacer el calculo de atención es necesario agregar una red feedforward adicional que tome las salida del encoder, se le aplique softmax al vector salida de la red y con eso obtendremos los pesos de cada uno de los bloques del vector de atención. La arquitectura de la red queda como se muestra a continuación: \n",
    "\n",
    "![arquitectura](./imagenes/atention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    \"\"\"Decodificador utilizando una red neuronal recursive con atención.\"\"\"\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        \"\"\"Inicializamos el decodificador basandonos en la arquitectura anterior\"\"\"\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size # Tamaño de la capa oculta\n",
    "        self.output_size = output_size # Tamaño del vector de salida\n",
    "        self.dropout_p = dropout_p     # Valor del dropout\n",
    "        self.max_length = max_length   # Tamaño máximo de la frase que se va a leer\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)     # Función para hacer el embedding\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)          # Activación Lineal\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size) # Vector que une el peso y atencion aplicada \n",
    "        self.dropout = nn.Dropout(self.dropout_p)                             # Aplicación de Bernouli para eliminar elementos\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \"\"\"Fase forward del Decoder.Bloques azules de la arquitectura\"\"\"\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0)) # Union de los vecotres encoder y attn weights\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"Inicializa el decodificador\"\"\"\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los datos para ser usado en la fase de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    \"\"\"Obtiene los indices dependiendo de la palabra\"\"\"\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    \"\"\"Convertimos una oración en un tensor\"\"\"\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    \"\"\"Convierte el Par de frases en Tensores\"\"\"\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "Para el entrenamiento de la red, debemos hacer que la red recuerde o tenga presente los resultados anteriores en y el estado de la capa oculta. Despues se le daba dar al decodificador una etiqueta de inicio de oración y la utilizará como el primer dato de entrada de la red. \n",
    "\n",
    "El concepto de `teacher_forcing_ratio` es el concepto de utilizar las salidas de target reales como cada entrada siguiente, en lugar de utilizarel decodificador como la siguiente entrada. Usar el `teacher_forcing_ratio` hace que converja más rápido hacia la solución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \"\"\"Funcion que nos da la base del entrenamiento del algoritmo\"\"\"\n",
    "\n",
    "    encoder_optimizer.zero_grad() # Limpia los gradiantes.\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    # Agregamos el token de BOS en el incio del tensor del decodificador\n",
    "    decoder_input = torch.tensor([[BOS]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Usamos teacher forcing para usar el target en el entrenamiento\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Sin el teacher forcing usamos las predicciones como input en el entrenamiento. \n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            # Si llega a EOS termina el ciclo\n",
    "            if decoder_input.item() == EOS:\n",
    "                break\n",
    "\n",
    "    loss.backward() # Calculamos BackPropagation\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de apoyo\n",
    "Creamos una serie de funciones de apoyo para que podamos medir tiempos d entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    \"\"\"Corre la fase de entrenamiento en un determinado número de iteraciones e imprime\n",
    "    los tiempos necesarios así como el loss que tiene el entrenamiento. Cuenta con los siguientes procesos:\n",
    "    \n",
    "        1) Comienza con el timer para calcular el tiempo de entrenamiento.\n",
    "        2) Inicializa los oprtimizadores y criterion\n",
    "        3) Crea los pares de entrenamiento\n",
    "        4) Crea los vectores de las graficas\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    # Para optimizar el encoder y decoder usamos Stochastic Gradient Descent (SGD)\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    # Para obtener el criterion usamos negative log likelihood loss (NLLLoss)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    \"\"\"Imprimimos ls gráfica\"\"\"\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar el Modelo\n",
    "Para probar el modelo seguimso un procedimiento similar al de entrenamietno pero en esta ocasión no le enviamos los targets al decodificador pero si lo alimentamos con las probabilidades que va obteniendo. Cuadno la probabilidad de EOS es muy alta es cuando el decodificador se detiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[BOS]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el metodo anterior para poder evaluar las frases y mostrar la frase original, el target y, por último, el output de la red seq2seq. Esto nos sirve para hacer la comparación entre lo que esperamos de resultado y lo que obtenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos el modelo\n",
    "Para entrenar el modelo, hicimos varias pruebas de sobre el numero de iteraciones óptimo ya que si entrenabamos con demasiadas iteraciones el \"loss\" aumentaba al final o si usabamos muy poco "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 30s (- 47m 31s) (1000 5%) 5.3746\n",
      "4m 53s (- 44m 3s) (2000 10%) 5.1583\n",
      "7m 14s (- 41m 0s) (3000 15%) 4.9700\n",
      "9m 40s (- 38m 41s) (4000 20%) 4.7750\n",
      "12m 4s (- 36m 13s) (5000 25%) 4.5432\n",
      "14m 31s (- 33m 54s) (6000 30%) 4.3629\n",
      "16m 58s (- 31m 32s) (7000 35%) 4.1569\n",
      "19m 30s (- 29m 15s) (8000 40%) 3.9300\n",
      "21m 59s (- 26m 53s) (9000 45%) 3.6441\n",
      "24m 29s (- 24m 29s) (10000 50%) 3.5987\n",
      "27m 6s (- 22m 10s) (11000 55%) 3.2824\n",
      "29m 39s (- 19m 46s) (12000 60%) 3.1099\n",
      "32m 22s (- 17m 26s) (13000 65%) 2.9756\n",
      "35m 0s (- 15m 0s) (14000 70%) 2.8072\n",
      "37m 42s (- 12m 34s) (15000 75%) 2.8006\n",
      "40m 18s (- 10m 4s) (16000 80%) 2.6489\n",
      "43m 1s (- 7m 35s) (17000 85%) 2.7290\n",
      "45m 38s (- 5m 4s) (18000 90%) 2.5496\n",
      "48m 18s (- 2m 32s) (19000 95%) 2.6260\n",
      "50m 58s (- 0m 0s) (20000 100%) 2.5824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = Encoder(input_lang.total, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoder(hidden_size, output_lang.total, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 20000, print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probar el Modelo\n",
    "Evaluamos el modelo con datos aleatorios para comparar la salida esperada y la salida obtenida de manera visual. Esto nos permite darnos una idea de que tan buena es la traducción que hace el sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> however when it comes to safety i am rather sceptical because safety in sweden for example is in principle no different from safety in germany italy or austria\n",
      "= per quanto riguarda la sicurezza invece sono piuttosto scettico in quanto la sicurezza in svezia non e sostanzialmente diversa dalla sicurezza in germania in italia o in austria\n",
      "< per quanto riguarda la la la quanto la sicurezza in quanto in in quanto in quanto in in quanto in in in quanto in la quanto in in in in in in in in in in in in in in in quanto in in in in dalla <EOS>\n",
      "\n",
      "> you will tell me that situations of growth or shortage do not affect everyone alike i agree with your analysis\n",
      "= mi ribatterete che la crescita o la penuria non valgono per tutti e sono pienamente d accordo con tali analisi\n",
      "< mi ribatterete che la crescita che non la la per valgono e la pienamente d accordo con il parlamento <EOS>\n",
      "\n",
      "> these days someone who lives in an old people s home is accommodated within the social field\n",
      "= oggi come oggi chi risiede in una casa per anziani e alloggiato in ambito sociale pero posso considerarlo anche come un cliente\n",
      "< oggi come oggi oggi chi risiede in una casa per anziani una casa anziani e alloggiato <EOS>\n",
      "\n",
      "> this is also important where the prerequisites for the internal market are concerned\n",
      "= limpatto di queste regole e importante anche ai fini del mercato interno\n",
      "< limpatto queste regole di di di queste regole di potenziamento non e regole di potenziamento <EOS>\n",
      "\n",
      "> we do not want to make the conditions of competition worse for some countries unilaterally and improve them for countries such as austria or other transit countries\n",
      "= non ci proponiamo di peggiorare unilateralmente le condizioni di concorrenza per alcuni paesi favorendo paesi di transito come laustria\n",
      "< non ci proponiamo di peggiorare unilateralmente la posizione dei mercati non ci proponiamo di la paesi che paesi l paesi e l l di il di <EOS>\n",
      "\n",
      "> as far as french planning experts are concerned for example the most probable scenario today is that of the entrenchment of regional disparities within each country\n",
      "= per gli esperti del piano francese lo scenario oggi piu plausibile e l approfondirsi del divario tra le regioni all interno di ogni paese\n",
      "< gli esperti del piano francese piu plausibile e lo scenario del divario di le regioni dell occupazione e un divario di lavoro e le regioni dellobiettivo della politica regionale <EOS>\n",
      "\n",
      "> due to the elections to the european parliament taking place around this time however parliament was not able to undertake its examination of these guidelines until after the text had been definitively adopted in july\n",
      "= vista l imminenza delle elezioni europee in pratica il parlamento ha potuto intraprendere l esame delle linee direttrici soltanto nel luglio quando il testo era stato gia adottato in via definitiva\n",
      "< vista l imminenza delle elezioni il il di ha il l il dei l il europea a delle l esame alla creazione <EOS>\n",
      "\n",
      "> the second point i would like to make and which i would have wished to make yesterday before the vote is that this parliament as other speakers remarked yesterday can only really have an effect if it works in close cooperation and synergy with the european commission\n",
      "= la mia seconda osservazione che avrei desiderato formulare ieri prima del voto e che il parlamento come altri onorevoli colleghi hanno ricordato ieri puo operare in modo davvero efficace solo se lavora in stretta cooperazione e sinergia con la commissione europea\n",
      "<  che un insegnamento la che che che e voto che voto voto onorevoli e saranno come hanno ricordato ma questa discussione sulla propria parte dei fondi strutturali e dei fondi di priorita per la temperatura ambiente <EOS>\n",
      "\n",
      "> i am very pleased with the level of support offered by your house to the commission in establishing these guidelines which have been submitted to the member states for information when establishing their own programmes\n",
      "= cio non puo che confortare la concezione fondata sulle buone pratiche tratte dall esperienza dei programmi per il periodo\n",
      "< cio che che non che confortare la commissione fondata fondata il che si dei trasporti <EOS>\n",
      "\n",
      "> mr president it is incumbent upon me to remind my colleague mr evans of why wales actually achieved objective status it was because of the discredited policies of his own conservative party\n",
      "= signor presidente sento il dovere di ricordare al mio collega onorevole evans il vero motivo per cui il galles ha ottenuto lo status di regione dellobiettivo e stato a causa delle sciagurate politiche del suo partito conservatore\n",
      "< signor presidente il il il dovere di ricordare al mio collega onorevole evans per il per motivo cui l onorevole evans ha delle per tra le <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909086\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "evaluations = 300\n",
    "\n",
    "def evalTranslator():\n",
    "    correctos = 0.0\n",
    "    for i in range(evaluations):\n",
    "        pair = random.choice(pairs)\n",
    "        tradGen, att = evaluate(encoder1, attn_decoder1, pair[0])\n",
    "        correctos += difflib.SequenceMatcher(lambda x: x == \" \", trad,tradG[:-6]).ratio()\n",
    "    acc = correctos / evaluations\n",
    "    return acc\n",
    "                                \n",
    "accuracy = evalTranslator()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Files...\n",
      "given that the commission is represented by vicepresident de palacio i believe that before voting it would help if the commission could let us know how ready it is to present this programme as agreed alternatively parliament is not ready to examine this programme as some appear to be suggesting\n"
     ]
    }
   ],
   "source": [
    "def readTestsFile(lang):\n",
    "    \"\"\"Lee el archivo de entrenamiento del traductor, lo limpia y asigna una clase Language\n",
    "    para almacenar los datos del lenguaje. Se permite revertir el orden para realizar pruebas\n",
    "    traduciendo de manera inversa el lenguaje.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading Evaluation...\")\n",
    "\n",
    "    # Abrimos el archivo y lo dividmos por salto de linea para obtener\n",
    "    # los pares en una sola linea.\n",
    "    lines = []\n",
    "    lines = open('./corpus/data3.eval', encoding='utf-8').read().strip().split('\\n')\n",
    "    #print(\"Found {} lines\".format(len(lines)))\n",
    "    return lines\n",
    "\n",
    "\n",
    "eval_sentence = readTestsFile('eng')\n",
    "print(random.choice(eval_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> agenda\n",
      "< per la proposta di la punto di vista del giorno <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = random.choice(eval_sentence)\n",
    "print('>', sentence)\n",
    "output_words, attentions = evaluate(encoder1, attn_decoder1, sentence)\n",
    "output_sentence = ' '.join(output_words)\n",
    "print('<', output_sentence)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Referencias\n",
    " \n",
    " - Basile, Pierpaolo, et al. “Bi-Directional LSTM-CNNs-CRF for Italian Sequence Labeling.” Proceedings of the Fourth Italian Conference on Computational Linguistics CLiC-It 2017, 2017, pp. 18–23., doi:10.4000/books.aaccademia.2339.\n",
    " - Raval, Siraj. “Recurrent Neural Network - The Math of Intelligence (Week 5).” YouTube, YouTube, 19 July 2017, www.youtube.com/watch?v=BwmddtPFWtA.\n",
    " - Raval, Siraj. “LSTM Networks - The Math of Intelligence (Week 8).” YouTube, YouTube, 9 Aug. 2017, www.youtube.com/watch?v=9zhrxE5PQgY. \n",
    " - Trask, Andrew. “Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN).” Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN) - i Am Trask, iamtrask.github.io/2015/11/15/anyone-can-code-lstm/.\n",
    " - PyTorch. “Translation with a Sequence to Sequence Network and Attention.” Translation with a Sequence to Sequence Network and Attention - PyTorch Tutorials 1.1.0 Documentation, pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html.\n",
    " - Ilya Sutskever. “Sequence to Sequence Learning with Neural Networks.” Cornell University, 10 Sept. 2014, arxiv.org/abs/1409.3215v3.\n",
    " - Cho, Kyunghyun, et al. “Learning Phrase Representations Using RNN Encoder–Decoder for Statistical Machine Translation.” Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 3 Sept. 2014, doi:10.3115/v1/d14-1179.\n",
    " - Luong, Thang, et al. “Effective Approaches to Attention-Based Neural Machine Translation.” Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, 2015, doi:10.18653/v1/d15-1166.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
